{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd59400a-14d6-4bdf-9b97-b84cde985f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('/data2/shreyas/multimodal/VLM')\n",
    "from vision_model import VisionEncoder\n",
    "from text_model import LLaMA\n",
    "from types import SimpleNamespace\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55fcbec5-83f8-4ec6-bcb2-8778596fa4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.vision_model = VisionEncoder(self.config.embed_dim)\n",
    "        self.text_model = LLaMA(self.config)\n",
    "\n",
    "    def forward(self, input_ids, pixel_values):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dbe3137-0139-4966-919d-fe5f6b300fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(SimpleNamespace):\n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "    def __getitem__(self, key):\n",
    "        return self.get(key)\n",
    "\n",
    "config = Config(\n",
    "    embed_dim = 576,\n",
    "    intermediate_dim = 1536,\n",
    "    max_position_embeddings = 8192,\n",
    "    base_theta = 100000,\n",
    "    num_q_heads = 9,\n",
    "    num_kv_heads = 3,\n",
    "    attn_dropout = 0.,\n",
    "    num_layers = 30,\n",
    "    vocab_size = 49152,\n",
    "    dtype = torch.bfloat16,\n",
    "    eos_token_id = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c00a6b3a-70f6-41d3-8478-a5b396628071",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleVLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8df10ff-df14-455e-8fc5-7163f2d2224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = ['q_proj',\n",
    "                 'k_proj',\n",
    "                 'v_proj',\n",
    "                 'o_proj',\n",
    "                 'gate_proj',\n",
    "                 'up_proj',\n",
    "                 'down_proj'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cf39796-395f-43cc-b300-f72ecb4c35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, alpha, lora_dropout=0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = linear_layer\n",
    "        for p in self.linear.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        self.in_features = self.linear.in_features\n",
    "        self.out_features = self.linear.out_features\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        std_dev = 1 / torch.sqrt(torch.tensor(self.rank).float())\n",
    "        \n",
    "        self.A = nn.Parameter(torch.randn(self.in_features, self.rank) * std_dev)\n",
    "        self.B = nn.Parameter(torch.zeros(self.rank, self.out_features))\n",
    "        self.dropout = nn.Dropout(lora_dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.linear(x)\n",
    "        x2 = self.alpha * (x @ self.A @ self.B)\n",
    "        x2 = self.dropout(x2)\n",
    "        return x1 + x2\n",
    "    \n",
    "    def merge(self):\n",
    "        self.linear.weight.data += self.alpha * (self.A @ self.B).T\n",
    "        return self.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a51951b-041c-4adb-b732-c2431791171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = Config(\n",
    "    rank=64,\n",
    "    alpha=128,\n",
    "    lora_dropout=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47edb1da-b53b-4368-bdb9-6208f9701d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_lora = partial(\n",
    "    LoRALinear,\n",
    "    rank=lora_config['rank'],\n",
    "    alpha=lora_config['alpha'],\n",
    "    lora_dropout=lora_config['lora_dropout']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f452e5be-a477-4172-9cd9-d3ed73a27c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = list(model.state_dict().keys())\n",
    "target_modules = [k for k in state_dict if 'text_model' in k and any([t in k for t in target_layers])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47ab65fd-5baa-4b31-9d80-0298d4860614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_model.layers.0.self_attn.q_proj.weight',\n",
       " 'text_model.layers.0.self_attn.k_proj.weight',\n",
       " 'text_model.layers.0.self_attn.v_proj.weight',\n",
       " 'text_model.layers.0.self_attn.o_proj.weight',\n",
       " 'text_model.layers.0.mlp.gate_proj.weight']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_modules[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9685da7f-fa21-4796-afb6-70cb3760874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for name, module in model.text_model.named_modules():\n",
    "    if any(name.endswith(t) for t in target_layers) and isinstance(module, nn.Linear):\n",
    "        parent_name = \".\".join(name.split(\".\")[:-1])  # Get parent module name\n",
    "        parent_module = model.text_model.get_submodule(parent_name)  # Get parent module reference\n",
    "        setattr(parent_module, name.split(\".\")[-1], apply_lora(module))  # Replace with LoRA-wrapped layer\n",
    "\n",
    "for layer in [model.vision_model.rms_norm, model.vision_model.avg_pool, model.vision_model.dim_proj]:\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eadb6bd4-dcfc-421c-bd35-0d5490f9a7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('19,981,056', '248,016,192')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{sum([p.numel() for p in model.parameters() if p.requires_grad]):,}\",f\"{sum([p.numel() for p in model.parameters()]):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba14a479-bf3a-4e47-be1e-d5f96a21b3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93963264, 154052928)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.vision_model.parameters()]),sum([p.numel() for p in model.text_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57bbf0ae-983d-4446-9fe4-7fc2322e401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.text_model.named_modules():\n",
    "#     if any(name.endswith(t) for t in target_layers) and isinstance(module, LoRALinear):\n",
    "#         parent_name = \".\".join(name.split(\".\")[:-1])  # Get parent module name\n",
    "#         parent_module = model.text_model.get_submodule(parent_name)  # Get parent module reference\n",
    "#         setattr(parent_module, name.split(\".\")[-1], module.merge())  # Replace with LoRA-wrapped layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3798120f-d8be-462f-a44a-dbfd975a02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([p.numel() for p in model.vision_model.parameters()]),sum([p.numel() for p in model.text_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "865b0d53-6bb4-4c20-abbf-f4d90b9b07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54169c44-0037-4f8f-88eb-24f7a349aac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['text_model.embed_tokens.weight'], [])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in params.keys() if 'embed_tokens' in t],[t for t in params.keys() if 'lm_head' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a267b37f-eebb-458f-bbef-0bca140c93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model):\n",
    "    # Group parameters by component and desired learning rate\n",
    "    \n",
    "    # Vision model components with high learning rate\n",
    "    vision_special_params = list(model.vision_model.rms_norm.parameters()) + \\\n",
    "                            list(model.vision_model.dim_proj.parameters())\n",
    "    \n",
    "    # LoraLinear instances with high learning rate\n",
    "    lora_params = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, LoRALinear):\n",
    "            lora_params.extend(module.parameters())\n",
    "    \n",
    "    # Text embeddings and LM head with low learning rate\n",
    "    # Since they're tied, we only need to include one of them\n",
    "    text_embed_params = list(model.text_model.embed_tokens.parameters())\n",
    "    \n",
    "    # Get all other parameters (which will use the base learning rate)\n",
    "    all_params = set(model.parameters())\n",
    "    special_params = set(vision_special_params + lora_params + text_embed_params)\n",
    "    base_params = list(all_params - special_params)\n",
    "    \n",
    "    # Create parameter groups with different learning rates\n",
    "    param_groups = [\n",
    "        {\"params\": base_params, \"lr\": 1e-5},\n",
    "        {\"params\": vision_special_params, \"lr\": 1e-4},  # Higher learning rate\n",
    "        {\"params\": lora_params, \"lr\": 1e-4},  # Higher learning rate\n",
    "        {\"params\": text_embed_params, \"lr\": 1e-5}  # Lower learning rate\n",
    "    ]\n",
    "    \n",
    "    return param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2bc647a-478b-4364-90ce-d452ca66a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(get_optimizer_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e9c2c1d-8506-44e1-9588-e20462ec2a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 1e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 2\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 3\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 1e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de93b93e-87d9-4c1d-82c5-24cb8733cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('19,981,056', '248,016,192')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{sum([p.numel() for p in model.parameters() if p.requires_grad]):,}\",f\"{sum([p.numel() for p in model.parameters()]):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63c75f-5743-42cb-93ae-7f18944d35c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
