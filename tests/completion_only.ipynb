{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4639f735-504b-444a-b8cf-82b0195b14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from processor import BlinkyProcessor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0328c3aa-e436-4782-ad60-3c98d9c46bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BlinkyProcessor('../Blinky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b699b18e-1a2a-498a-92e7-a24383f6c309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='../Blinky', vocab_size=49152, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|im_start|>', 'eos_token': '<|im_end|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|im_end|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<repo_name>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<reponame>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t5: AddedToken(\"<file_sep>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t6: AddedToken(\"<filename>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t7: AddedToken(\"<gh_stars>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8: AddedToken(\"<issue_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t9: AddedToken(\"<issue_comment>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t10: AddedToken(\"<issue_closed>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t11: AddedToken(\"<jupyter_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t12: AddedToken(\"<jupyter_text>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t13: AddedToken(\"<jupyter_code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t14: AddedToken(\"<jupyter_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15: AddedToken(\"<jupyter_script>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t16: AddedToken(\"<empty_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05fe323f-8f96-49bd-82f0-0d3f43a9f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    {'text': [{'role':'user','content': 'hello, how are you?'}, {'role': 'assistant', 'content': 'hi i am blinky a VLM'}], 'image': Image.open('cat.jpg')}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83fe9e4-8945-4c4f-a61a-fb3352c64d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = processor(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e056c19a-cb88-418c-8081-4082d67378ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 <|im_start|>\n",
      "1 9690 system\n",
      "2 198 \n",
      "\n",
      "3 2683 You\n",
      "4 359  are\n",
      "5 253  a\n",
      "6 5356  helpful\n",
      "7 5646  AI\n",
      "8 11173  assistant\n",
      "9 3365  named\n",
      "10 2114  Bl\n",
      "11 900 ink\n",
      "12 105 y\n",
      "13 351  with\n",
      "14 37063  multim\n",
      "15 32058 odal\n",
      "16 7596  capabilities\n",
      "17 28 ,\n",
      "18 7018  trained\n",
      "19 411  by\n",
      "20 443  sh\n",
      "21 257 re\n",
      "22 4198 yd\n",
      "23 276 an\n",
      "24 2 <|im_end|>\n",
      "25 198 \n",
      "\n",
      "26 1 <|im_start|>\n",
      "27 4093 user\n",
      "28 198 \n",
      "\n",
      "29 28120 hello\n",
      "30 28 ,\n",
      "31 638  how\n",
      "32 359  are\n",
      "33 346  you\n",
      "34 47 ?\n",
      "35 2 <|im_end|>\n",
      "36 198 \n",
      "\n",
      "37 1 <|im_start|>\n",
      "38 520 ass\n",
      "39 9531 istant\n",
      "40 198 \n",
      "\n",
      "41 6004 hi\n",
      "42 2056  i\n",
      "43 744  am\n",
      "44 39889  blink\n",
      "45 105 y\n",
      "46 253  a\n",
      "47 717  V\n",
      "48 34519 LM\n",
      "49 2 <|im_end|>\n",
      "50 198 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, token in enumerate(x['input_ids'].flatten().numpy()):\n",
    "    print(idx, token, processor.tokenizer.decode([token],skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07cd87d9-842a-4fa2-8d86-23500064851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode([198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ef50aca-9e65-4819-a010-e650b0fe6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02593ad5-c38c-4a66-a54b-f95020385733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  9690,   198,  2683,   359,   253,  5356,  5646, 11173,  3365,\n",
       "          2114,   900,   105,   351, 37063, 32058,  7596,    28,  7018,   411,\n",
       "           443,   257,  4198,   276,     2,   198,     1,  4093,   198, 28120,\n",
       "            28,   638,   359,   346,    47,     2,   198,     1,   520,  9531,\n",
       "           198,  6004,  2056,   744, 39889,   105,   253,   717, 34519,     2,\n",
       "           198]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf84d0bf-c3e0-403b-b720-a85fc9a12ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 26, 37])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_start_positions = torch.where(input_ids[0]==1)[0]\n",
    "im_start_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d47d8f05-28b2-4e3e-8dc5-ed59fcbe9732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 520, 9531, 198], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_tokens = processor.tokenizer('<|im_start|>assistant\\n')\n",
    "assistant_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10b7d042-ff88-43c7-a9a1-03527ef626ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) False\n",
      "tensor(26) False\n",
      "tensor(37) True\n"
     ]
    }
   ],
   "source": [
    "for pos in im_start_positions:\n",
    "    matched = False\n",
    "    for i,token in enumerate(assistant_tokens['input_ids']):\n",
    "        curr_pos = pos+i\n",
    "        if input_ids[0][curr_pos] != token:\n",
    "            break\n",
    "    else:\n",
    "        matched = True        \n",
    "    print(pos, matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13b5cf45-9d43-4f2f-972c-a26463849419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_for_completion_only(samples, assistant_template='<|im_start|>assistant\\n',chat_start_token_id=1):\n",
    "    inputs = processor(samples)\n",
    "    labels = inputs['input_ids'].clone()\n",
    "    labels[:, :-1] = labels[:, 1:].clone()\n",
    "    padding_mask = (inputs['attention_mask'] == 0)\n",
    "    labels[padding_mask] = -100\n",
    "    inputs['labels'] = labels\n",
    "\n",
    "    assistant_positions = []\n",
    "    assistant_tokens = processor.tokenizer(assistant_template)['input_ids']\n",
    "    \n",
    "    for batch_idx in range(inputs['input_ids'].shape[0]):\n",
    "        im_start_positions = torch.where(inputs['input_ids'][batch_idx]==chat_start_token_id)[0]\n",
    "        for pos in im_start_positions:\n",
    "            matched = False\n",
    "            for i,token in enumerate(assistant_tokens):\n",
    "                curr_pos = pos+i\n",
    "                if inputs['input_ids'][batch_idx][curr_pos] != token:\n",
    "                    break\n",
    "            else:\n",
    "                matched = True\n",
    "        if matched:\n",
    "            assistant_positions.append(pos)\n",
    "\n",
    "    assert len(assistant_positions) == inputs['input_ids'].shape[0], \"a sample in this batch doesn't contain the assistant_template\"\n",
    "\n",
    "    for batch_idx in range(inputs['input_ids'].shape[0]):\n",
    "        inputs['labels'][batch_idx, :assistant_positions[batch_idx]-1] = -100\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a210a83f-0afa-4de8-9f2a-d89d1c29174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    {'text': [{'role':'user','content': 'hello, how are you?'}, {'role': 'assistant', 'content': 'hi i am blinky a VLM'}], 'image': Image.open('cat.jpg')},\n",
    "    {'text': [{'role':'user','content': 'this is a test!'}, {'role': 'assistant', 'content': 'heyyy :)'}], 'image': Image.open('cat.jpg')}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f6ddc0e-c6ce-423f-aa6d-e64b01d8f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = collate_fn_for_completion_only(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca845d51-5f44-452f-89c4-66a2759a3e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,  9690,   198,  2683,   359,   253,  5356,  5646, 11173,  3365,\n",
       "         2114,   900,   105,   351, 37063, 32058,  7596,    28,  7018,   411,\n",
       "          443,   257,  4198,   276,     2,   198,     1,  4093,   198, 28120,\n",
       "           28,   638,   359,   346,    47,     2,   198,     1,   520,  9531,\n",
       "          198,  6004,  2056,   744, 39889,   105,   253,   717, 34519,     2,\n",
       "          198])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1dd04db2-45d6-4311-8bf5-e61085c4e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,     1,   520,  9531,   198,\n",
       "         6004,  2056,   744, 39889,   105,   253,   717, 34519,     2,   198,\n",
       "          198])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['labels'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
