{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a88f381-ea65-4bf0-894c-59bc0b1e6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from transformers import AutoTokenizer\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d49e6a-6c2f-4f15-80f6-875b23ec528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat.jpg\t\t    full_model.ipynb  peft.ipynb\t       __pycache__\n",
      "dataset.ipynb\t    kv-caching.ipynb  prefix-lm-masking.ipynb  tests.ipynb\n",
      "embeddings_test.py  llama.py\t      preprocessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a526d408-cb89-4a76-9d72-1924400fa202",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('../Blinky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c281d964-87db-42db-8847-31b8e4c868db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful AI assistant named Blinky with multimodal capabilities, trained by shreydan<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268da6f3-60d7-4f17-9df8-50f5bdfdb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chat_template = \"<|start_of_image|><|image_token|><|end_of_image|>\"+tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "420bd4a9-f09a-4475-a9f9-299c8ba98426",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = new_chat_template\n",
    "tokenizer.chat_template = tokenizer.chat_template.replace(\n",
    "    \"You are a helpful AI assistant named SmolLM, trained by Hugging Face\",\n",
    "    \"You are a helpful AI assistant named SimpleVLM with multimodal capabilities, trained by shreydan\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14ccb7a-b159-4585-994e-d2ea603b43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [{'role':'user','content':'what is the color of the cup?'}]\n",
    "inputs = tokenizer.apply_chat_template(sample, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a1aaa5-024c-4567-b508-6a8449ac1cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_of_image|><|image_token|><|end_of_image|><|im_start|>system\n",
      "You are a helpful AI assistant named Blinky with multimodal capabilities, trained by shreydan<|im_end|>\n",
      "<|im_start|>user\n",
      "what is the color of the cup?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07277c4a-4256-4a4f-8e1b-aec0ceacd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self, tokenizer_path, num_image_tokens=256):\n",
    "        self.tokenizer_path = tokenizer_path\n",
    "        self.image_size = 512\n",
    "        self.num_image_tokens = 256\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_path)\n",
    "        \n",
    "        self.img_mean = [0.5,0.5,0.5]\n",
    "        self.img_std = [0.5,0.5,0.5]\n",
    "        self.img_transforms = T.Compose([\n",
    "            T.Resize((self.image_size, self.image_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=self.img_mean, std=self.img_std)\n",
    "        ])\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        return self.img_transforms(image.convert('RGB'))\n",
    "\n",
    "    def _add_img_tokens(self, text):\n",
    "        tokens = \"<|start_of_image|><|image_token|><|end_of_image|>\"\n",
    "        tokens = tokens.replace(\"<|image_token|>\",\"<|image_token|>\"*self.num_image_tokens)\n",
    "        return f\"{tokens}\\n{text}\"\n",
    "        \n",
    "    def apply_chat_template(self, samples, use_system_prompt=True):\n",
    "        chat_texts = self.tokenizer.apply_chat_template(\n",
    "            samples, \n",
    "            tokenize=False\n",
    "        )\n",
    "        chat_texts = [\n",
    "            self._add_img_tokens(chat_text)\n",
    "            for chat_text in chat_texts\n",
    "        ]\n",
    "        return chat_texts\n",
    "\n",
    "    def tokenize_and_pad(self, texts):\n",
    "        tokenized = [processor.tokenizer.encode(t,return_tensors='pt',truncation=True,max_length=1024).squeeze(0) for t in texts]\n",
    "        max_length = max(t.shape[0] for t in tokenized)\n",
    "        tokenized = [\n",
    "            F.pad(t,[0,max_length-t.shape[0]],value=self.tokenizer.pad_token_id)\n",
    "            for t in tokenized\n",
    "        ] # right padding\n",
    "        return torch.vstack(tokenized)\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        texts = self.apply_chat_template([s['text'] for s in samples])\n",
    "        input_ids = self.tokenize_and_pad(texts)\n",
    "        images = torch.vstack([self.preprocess_image(s['image']).unsqueeze(0) for s in samples])\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'pixel_values': images\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe90514-313b-4c1c-95ba-8c6bdce60e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor= Processor('../Blinky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9998ae8-1b1c-416d-80f0-47a593d16c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    [{'role':'user','content':'what is the color of the cup?'}],\n",
    "    [{'role':'user','content':'what is the meaning of life? is it even real?'}]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc26ce9-a701-4279-88fd-18da6c2f7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e1d561a-a23b-4952-bf15-f48eaa448a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(np.random.rand(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e8d0f3-4048-4d15-8c04-771cfca04f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    {'text':[{'role':'user','content':'what is the color of the cup?'}], 'image': im},\n",
    "    {'text': [{'role':'user','content':'what is the meaning of life? is it even real?'}], 'image': im}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3110d115-456b-4848-906a-068b5fabf78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful AI assistant named Blinky with multimodal capabilities, trained by shreydan<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad5f933-4711-4c1b-9707-091606217803",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=processor.apply_chat_template([s['text'] for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04e29b4c-d179-4b48-8a1f-efbb9a9c1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "074cb256-4f38-4338-a3fd-d22ff53c7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=[a for a in re.findall(r'<|image_token|>',x[0]) if a=='image_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da76f4f-fbbd-480d-a050-5d219ef868cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aacddb7-275b-421f-bdae-2cf5df34d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processor(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85601c9-20c0-444a-9db2-748496d497e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bd54276-df6b-4fb2-9139-d5a75e37e2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([2, 302]),\n",
       " 'pixel_values': torch.Size([2, 3, 512, 512])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v.shape for k,v in processed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54eb23b9-07cf-4c7b-bad1-e80564de4bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49152, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49153,   198,     1,\n",
       "         9690,   198,  2683,   359,   253,  5356,  5646, 11173,  3365,  2114,\n",
       "          900,   105,   351, 37063, 32058,  7596,    28,  7018,   411,   443,\n",
       "          257,  4198,   276,     2,   198,     1,  4093,   198,  5588,   314,\n",
       "          260,  2380,   282,   260,  7118,    47,     2,   198,     2,     2,\n",
       "            2,     2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bfe6ab3-24b7-4cff-ac54-564c29cdf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = processed['input_ids'].clone()\n",
    "labels[:,:-1] = labels[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001a126-29f4-4736-908a-ba9098dac770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ee39838-fca2-4d85-a843-71e6fa104a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49152, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49153,   198,     1,\n",
       "         9690,   198,  2683,   359,   253,  5356,  5646, 11173,  3365,  2114,\n",
       "          900,   105,   351, 37063, 32058,  7596,    28,  7018,   411,   443,\n",
       "          257,  4198,   276,     2,   198,     1,  4093,   198,  5588,   314,\n",
       "          260,  2380,   282,   260,  7118,    47,     2,   198,     2,     2,\n",
       "            2,     2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a751307-9e60-478e-8206-be8c86e8f6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154, 49154,\n",
       "        49154, 49154, 49154, 49154, 49154, 49154, 49153,   198,     1,  9690,\n",
       "          198,  2683,   359,   253,  5356,  5646, 11173,  3365,  2114,   900,\n",
       "          105,   351, 37063, 32058,  7596,    28,  7018,   411,   443,   257,\n",
       "         4198,   276,     2,   198,     1,  4093,   198,  5588,   314,   260,\n",
       "         2380,   282,   260,  7118,    47,     2,   198,     2,     2,     2,\n",
       "            2,     2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b85cca1-b839-42af-8c67-0f24197854eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = labels.clone()\n",
    "for ignore_token in [49154,49152,49153]:\n",
    "    mask = (labels==ignore_token).long()\n",
    "    masked_labels[mask==1] = -100\n",
    "padding_mask = (processed['input_ids']==processor.tokenizer.pad_token_id).long()\n",
    "masked_labels[padding_mask==1] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c101a46-c8c0-4314-864f-cd19b50d0fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,   198,     1,  9690,\n",
       "          198,  2683,   359,   253,  5356,  5646, 11173,  3365,  2114,   900,\n",
       "          105,   351, 37063, 32058,  7596,    28,  7018,   411,   443,   257,\n",
       "         4198,   276,     2,  -100,     1,  4093,   198,  5588,   314,   260,\n",
       "         2380,   282,   260,  7118,    47,     2,  -100,     2,  -100,  -100,\n",
       "         -100,  -100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a6ce-eaea-4ae6-b750-885b35490ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
